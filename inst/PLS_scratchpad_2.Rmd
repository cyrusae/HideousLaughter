---
title: "PLS scratchpad 2"
output: html_notebook
---

REFACTOR x2: WHEN IT WORKS ALL THE WAY THROUGH
- use `targets`
- audit dependencies
- move dependencies to package project as a whole 

REFACTOR x3: MOVE TO CANONICAL PACKAGE FORM
- add unit tests 

## get download URLs set up 
```{r setup}
require(rvest) #web scraping (access PLS site)
require(stringr) #string management 
require(magrittr) #pipe
require(data.table) #manage data
require(purrr) #make functions better
require(furrr) #parallel processing 
require(here) #file path management 
 # TODO maybe replace with lower-level `rprojroot` when able 
require(assertthat) #expect conditions in functions/throw errors
require(assertr) #data validation 

url <- 'https://www.imls.gov/research-evaluation/data-collection/public-libraries-survey'
```
```{r urls}
pls <- rvest::read_html(url) %>% 
  rvest::html_nodes(xpath = '//*[@data-ui-role="accordion"]') %>%
  rvest::html_children() %>% #the accordion contains years
  rvest::html_element('a') %>% #get the first link 
  rvest::html_attrs() #get the url that link refers to
pls <- pls[grepl('*pls_fy', pls)] #reduce to real links
pls <- paste0('https://www.imls.gov', pls) #list of download URLs for zip files
names(pls) <- stringr::str_extract(pls, 'fy20..') #list now has name of the FY each URL is for 
```

```{r zips}
# TODO: Generalize into a function and test (it now works for individuals)
test <- pls[1]
assertthat::is.string(test)
if (is.null(names(test))) {
  names(test) <- stringr::str_extract(test, 'fy20..')
}
assertthat::assert_that(!is.null(names(test)))
fp <- here::here('data', 'raw', 'PLS_csvs', names(test))
if (!dir.exists(fp)) {
  dir.create(fp)
}
assertthat::is.writeable(fp)
zipfile <- paste0(fp, '/', names(test), '.zip')
if (!file.exists(zipfile)) {
  download.file(url = test, destfile = zipfile)
}
assertthat::is.readable(zipfile)
zip_contents <- grep('*.csv$', #find only the CSV files 
                     unzip(zipfile = zipfile, list = TRUE)$Name,
                     ignore.case = TRUE, value = TRUE)
unzip(zipfile = zipfile, files = zip_contents,
      exdir = fp) #put the CSV files in the /fy20XX/ directory
zip_contents <- grep('*.csv$', list.files(fp, full.names = TRUE),
                     ignore.case = TRUE, value = TRUE)
zip_results <- data.table::data.table(path = zip_contents,
             filename = rep_len(names(test), 3),
             nrows = NA)
check_nrow <- \(filename) {
  n <- data.table::fread(file = filename, select = 1L) %>%
    nrow()
}
zip_nrows <- purrr::map_int(.x = zip_results$path, 
                            .f = check_nrow)
zip_results$nrows <- zip_nrows #label file by number of rows
zip_results[nrows == max(zip_results$nrows), #max nrows will be outlet file
            filename := paste0(fp, '/pls_', filename,
                               '_outlet.csv')]
zip_results <- zip_results[nrows != min(zip_results$nrows),] #drop state file
zip_results[nrows == min(zip_results$nrows), #new minimum will be administrative entities file
            filename := paste0(fp, '/pls_', filename, '_AE.csv')]
file.rename(zip_results$path, zip_results$filename) #rename AE and outlet files 
zip_unneeded <- list.files(fp, full.names = TRUE) %>%
  setdiff(zip_results$filename) #files not matching our labelled desirable ones go into the void now
file.remove(zip_unneeded)
 # TODO add assertthat check that the desirable files are readable as expected 
# TODO conversely, remove unnecessary assertthats once I can tell where I'm being--well--overly defensive 

```

 - 4/01 question: do I actually want each FY to have its own subdirectory...? I guess it avoids collisions with other files? It may just be safer on balance. We'll see how it affects later processing. 
 
Next:
- Generalize to function
- Test/run for all
- Next phase of cleaning! 

---

Intended behavior: Phases of functions in `pls.R`
1. `get_pls_urls()` -- finished(!) -- returns a vector of desirable URLs with FYs as names (see above `{r urls}`)

```{r}
pls <- get_pls_urls()
```


2. `(name tk)` -- ingests one item from (1), downloads zip file, unpacks it, identifies and renames the outlet and AE response files, bins the rest, returns path to outlet and AE files.

```{r}
get_pls_zip <- \(url = url,
                 extract = 'fy20..',
                 here = 'data/raw/PLS_csvs') {
  assertthat::is.string(url) #check for receiving one (1) url
  assertthat::assert_that(is.character(here)) #check for viable path requests
  if (is.null(names(url))) { #make sure we have a FY name
    fy <- stringr::str_extract(url, extract)
    assertthat::assert_that(nchar(fy) == nchar(extract))
    names(url) <- fy
  }
  fy <- names(url)
  fp <- paste0(here::here(here), '/', fy) #subdirectory named for the FY
  if (!dir.exists(fp)) {
    dir.create(fp)
  } #create subdirectory if needed
  assertthat::is.writeable(fp) #make sure it is usable now
  zipfile <- paste0(fp, '/', fy, '.zip') #filename for zip download
  if (!file.exists(zipfile)) download.file(url = url, 
                                           destfile = zipfile)
  assertthat::is.readable(zipfile) #is downloaded zip readable?
  zip_contents <- grep('*.csv$', #find only the CSV files 
                     unzip(zipfile = zipfile, list = TRUE)$Name,
                     ignore.case = TRUE, value = TRUE)
  unzip(zipfile = zipfile, files = zip_contents,
      exdir = fp) #put the CSV files in the /fy20XX/ directory
  zip_contents <- grep('*.csv$', #get paths to the unzipped CSVs
                       list.files(fp, full.names = TRUE),
                       ignore.case = TRUE, value = TRUE)
  assertthat::assert_that(length(zip_contents) == 3) #make sure there are specifically three CSV files here
  zip_nrows <- check_nrows(files = zip_contents)
  zip_results <- data.table::data.table(path = zip_contents,
                                        nrows = zip_nrows)
  zip_results <- zip_results[nrows != min(zip_results$nrows), ] #remove the shortest CSV file (will be the state results)
  zip_results[nrows == max(zip_results$nrows), #longest = outlets
              filename := paste0(fp, '/pls_outlet_', fy, '.csv')]
  zip_results[nrows == min(zip_results$nrows), #remaining = administrative entities 
              filename := paste0(fp, '/pls_admin_', fy, '.csv')]
  file.rename(from = zip_results$path, 
              to = zip_results$filename)
  zip_results$filename #return the relevant files 
}
```
```{r}
year <- get_pls_zip(pls[1])
```


3. `(name tk)` -- takes result of (2), removes known NA-equivalent values ("M" and whole negative integers and the nonresponse flags), saves clean CSV (intended/hoped-for behavior: have this mean more of the data types are correct the first time). (*TODO:* Can some date handling/sanitization happen here or does it need to be later?)
```{r}
pg <- data.table::fread(file = year[1])
pg_cl <- pg 
#pg_cl[pg_cl %ilike% '^-\\d{1}$', ] #no

#There is a native data.table solution for this that won't require copying, but it's not currently working, so copies we shall have for now.
pg_cl[pg_cl == -9] <- NA #Suppressed
pg_cl[pg_cl == -4] <- NA #Closed
pg_cl[pg_cl == -3] <- NA #Closed
pg_cl[pg_cl == -1] <- NA #No response
pg_cl[pg_cl == 'M'] <- NA #Overall 'M' is used as NA/Missing
pg_cl[MICROF == 'N', MICROF := NA]  #MICROF uses N as NA/Missing
pg_cl[RSTATUS == 3, RSTATUS := NA]  #Non-respondent, not imputed

```


```{r}
get_pls_csv <- \(file, 
                 extract = 'fy20..',
                 here = 'data/raw/PLS_csvs') {
  assertthat::is.readable(file)
  filename <- stringr::str_extract(file, 'pls_\\w+_fy20..\\.csv$') #get the name of the file only, for later 
  dest <- paste0(here::here(here), '/', filename)
  dt <- data.table::fread(file = file)
  dt[dt == -9] <- NA #Remove suppressed data
  dt[dt == -4] <- NA #Remove for closures
  dt[dt == -3] <- NA #Remove for closures
  dt[dt == -1] <- NA #Remove unanswered questions
  dt[dt == 'M'] <- NA #Remove missing values
  if ('MICROF' %in% names(dt)) dt[MICROF == 'N', MICROF := NA] #NA for the MICROF field only
  if ('RSTATUS' %in% names(dt)) dt[RSTATUS == 3, RSTATUS := NA] #remove nonrespondents 
  data.table::fwrite(dt, file = dest)
  assertthat::is.readable(path = dest)
  dest
}

```
```{r}
furrr::future_map(.x = year, .f = get_pls_csv)
```


4. `(chore tk)` -- figure out best way to vectorize (2) and (3) over the results of (1) without duplicating work
5. **(regroup for strategy here)** -- this is the part where we get to actually combine the files. Alexander if you don't stop and reevaluate how to do so when you get here I will punt you like the football.

---

04/02 breakpoint: Now that both halves of the functionality work, I'd like to combine get_pls_zip and get_pls_csv. Currently there's back-and-forth redundancy happening that wouldn't be an issue if metadata was persisting instead of being reduced to a return.

GOTO scratchpad #3 maybe?
