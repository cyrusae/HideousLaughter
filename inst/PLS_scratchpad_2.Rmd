---
title: "PLS scratchpad 2"
output: html_notebook
---

REFACTOR x2: WHEN IT WORKS ALL THE WAY THROUGH
- use `targets`
- audit dependencies
- move dependencies to package project as a whole 

REFACTOR x3: MOVE TO CANONICAL PACKAGE FORM
- add unit tests 

## get download URLs set up 
```{r setup}
require(rvest) #web scraping (access PLS site)
require(stringr) #string management 
require(magrittr) #pipe
require(data.table) #manage data
require(purrr) #make functions better
require(furrr) #parallel processing 
require(here) #file path management 
 # TODO maybe replace with lower-level `rprojroot` when able 
require(assertthat) #expect conditions in functions/throw errors
require(assertr) #data validation 

url <- 'https://www.imls.gov/research-evaluation/data-collection/public-libraries-survey'
```
```{r}
pls <- rvest::read_html(url) %>% 
  rvest::html_nodes(xpath = '//*[@data-ui-role="accordion"]') %>%
  rvest::html_children() %>% #the accordion contains years
  rvest::html_element('a') %>% #get the first link 
  rvest::html_attrs() #get the url that link refers to
pls <- pls[grepl('*pls_fy', pls)] #reduce to real links
pls <- paste0('https://www.imls.gov', pls) #list of download URLs for zip files
names(pls) <- stringr::str_extract(pls, 'fy20..') #list now has name of the FY each URL is for 
```

```{r}
# TODO: Generalize into a function and test (it now works for individuals)
test <- pls[1]
assertthat::is.string(test)
if (is.null(names(test))) {
  names(test) <- stringr::str_extract(test, 'fy20..')
}
assertthat::assert_that(!is.null(names(test)))
fp <- here::here('data', 'raw', 'PLS_csvs', names(test))
if (!dir.exists(fp)) {
  dir.create(fp)
}
assertthat::is.writeable(fp)
zipfile <- paste0(fp, '/', names(test), '.zip')
if (!file.exists(zipfile)) {
  download.file(url = test, destfile = zipfile)
}
assertthat::is.readable(zipfile)
zip_contents <- grep('*.csv$', #find only the CSV files 
                     unzip(zipfile = zipfile, list = TRUE)$Name,
                     ignore.case = TRUE, value = TRUE)
unzip(zipfile = zipfile, files = zip_contents,
      exdir = fp) #put the CSV files in the /fy20XX/ directory
zip_contents <- grep('*.csv$', list.files(fp, full.names = TRUE),
                     ignore.case = TRUE, value = TRUE)
zip_results <- data.table::data.table(path = zip_contents,
             filename = rep_len(names(test), 3),
             nrows = NA)
check_nrow <- \(filename) {
  n <- data.table::fread(file = filename, select = 1L) %>%
    nrow()
}
zip_nrows <- purrr::map_int(.x = zip_results$path, 
                            .f = check_nrow)
zip_results$nrows <- zip_nrows #label file by number of rows
zip_results[nrows == max(zip_results$nrows), #max nrows will be outlet file
            filename := paste0(fp, '/pls_', filename,
                               '_outlet.csv')]
zip_results <- zip_results[nrows != min(zip_results$nrows),] #drop state file
zip_results[nrows == min(zip_results$nrows), #new minimum will be administrative entities file
            filename := paste0(fp, '/pls_', filename, '_AE.csv')]
file.rename(zip_results$path, zip_results$filename) #rename AE and outlet files 
zip_unneeded <- list.files(fp, full.names = TRUE) %>%
  setdiff(zip_results$filename) #files not matching our labelled desirable ones go into the void now
file.remove(zip_unneeded)
 # TODO add assertthat check that the desirable files are readable as expected 
# TODO conversely, remove unnecessary assertthats once I can tell where I'm being--well--overly defensive 

```

 - 4/01 question: do I actually want each FY to have its own subdirectory...? I guess it avoids collisions with other files? It may just be safer on balance. We'll see how it affects later processing. 
 
Next:
- Generalize to function
- Test/run for all
- Next phase of cleaning! 
